import os
import pandas as pd
import torch
from tqdm import tqdm
import pickle

from config import get_config
from datasets import CarDataset
from models import get_models, BrandModel
from transforms import get_val_transform, get_tta_transforms



def load_brand_model(config, device):
    """ë¸Œëœë“œ ë¶„ë¥˜ ëª¨ë¸ ë¡œë“œ"""
    brand_model_path = config.brand_model_path
    brand_info_path = config.brand_info_path

    if not os.path.exists(brand_model_path) or not os.path.exists(brand_info_path):
        print("âš ï¸  ë¸Œëœë“œ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë¸Œëœë“œ ì˜ˆì¸¡ ìƒëµ.")
        return None, None

    # ë¸Œëœë“œ ì •ë³´ ë¡œë“œ
    with open(brand_info_path, "rb") as f:
        brand_info = pickle.load(f)

    num_brands = len(brand_info["brands"])
    print(f"ğŸ·ï¸  ë¸Œëœë“œ ìˆ˜: {num_brands}")
    print(f"ğŸ·ï¸  ë¸Œëœë“œ ëª©ë¡: {brand_info['brands']}")

    # ë¸Œëœë“œ ëª¨ë¸ ìƒì„± ë° ë¡œë“œ
    brand_model = BrandModel(num_brands).to(device)

    # ê°€ì¤‘ì¹˜ ë¡œë“œ
    brand_model.load_state_dict(torch.load(brand_model_path, map_location="cpu"))
    brand_model.eval()

    print(f"âœ… ë¸Œëœë“œ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {brand_model_path}")
    return brand_model, brand_info


def generate_test_brand_predictions(brand_model, brand_info, test_dataset, device):
    """í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ëŒ€í•œ ë¸Œëœë“œ ì˜ˆì¸¡ ìƒì„±"""
    if brand_model is None:
        return {}

    brand_model = brand_model.to(device)
    brand_model.eval()

    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë” ìƒì„±
    test_loader = torch.utils.data.DataLoader(
        test_dataset,
        batch_size=64,  # ë¸Œëœë“œ ì˜ˆì¸¡ìš©ìœ¼ë¡œ í° ë°°ì¹˜ ì‚¬ìš©
        shuffle=False,
        num_workers=4,
        pin_memory=True,
    )

    brand_predictions = {}

    print("ğŸ”® í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¸Œëœë“œ ì˜ˆì¸¡ ìƒì„± ì¤‘...")
    with torch.no_grad():
        for batch_idx, batch_data in enumerate(
            tqdm(test_loader, desc="Generating brand predictions")
        ):
            # í…ŒìŠ¤íŠ¸ ë°ì´í„°ëŠ” ì´ë¯¸ì§€ë§Œ ìˆìŒ
            if test_dataset.tta_transforms is not None:
                # TTA ì‚¬ìš© ì‹œ: [batch_size, num_tta, channels, height, width]
                images = batch_data
                images = images.mean(dim=1)  # TTA ì´ë¯¸ì§€ë“¤ì˜ í‰ê· 
            else:
                # ì¼ë°˜ì ì¸ ê²½ìš°: [batch_size, channels, height, width]
                images = batch_data

            images = images.to(device)
            outputs = brand_model(images)
            probabilities = torch.softmax(outputs, dim=1)

            # ë°°ì¹˜ì˜ íŒŒì¼ëª…ë“¤ ê°€ì ¸ì˜¤ê¸°
            batch_start = batch_idx * test_loader.batch_size
            batch_end = min(batch_start + test_loader.batch_size, len(test_dataset))

            for i in range(batch_end - batch_start):
                # í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ íŒŒì¼ ê²½ë¡œì—ì„œ íŒŒì¼ëª… ì¶”ì¶œ
                img_path = test_dataset.data[batch_start + i]
                filename = os.path.basename(img_path)

                # ë¸Œëœë“œ í™•ë¥  ì €ì¥
                brand_predictions[filename] = probabilities[i].cpu().numpy()

    print(f"âœ… í…ŒìŠ¤íŠ¸ ë¸Œëœë“œ ì˜ˆì¸¡ ì™„ë£Œ: {len(brand_predictions)}ê°œ")
    return brand_predictions


def predict(models, images, brand_features=None):
    """ëª¨ë¸ ì•™ìƒë¸” ì˜ˆì¸¡"""
    predictions = []

    for model in models:
        model.eval()
        with torch.no_grad():
            if (
                brand_features is not None
                and hasattr(model, "forward")
                and "brand_logits" in model.forward.__code__.co_varnames
            ):
                # AdvancedModel - ë¸Œëœë“œ ì •ë³´ ì‚¬ìš©
                output = model(images, brand_features)
            else:
                # ì¼ë°˜ ëª¨ë¸
                output = model(images)
            predictions.append(torch.softmax(output, dim=1))

    # ì•™ìƒë¸” í‰ê· 
    ensemble_prediction = torch.stack(predictions).mean(dim=0)
    return ensemble_prediction


def predict_with_tta(models, images, brand_features=None):
    """TTAë¥¼ ì‚¬ìš©í•œ ì˜ˆì¸¡"""
    tta_predictions = []

    # TTA ì´ë¯¸ì§€ë“¤ì— ëŒ€í•´ ì˜ˆì¸¡
    for i in range(images.shape[1]):  # TTA ì°¨ì›
        tta_image = images[:, i]  # [batch_size, channels, height, width]
        prediction = predict(models, tta_image, brand_features)
        tta_predictions.append(prediction)

    # TTA ê²°ê³¼ í‰ê· 
    return torch.stack(tta_predictions).mean(dim=0)


def evaluate():
    config = get_config()
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"Using device: {device}")

    # í´ë˜ìŠ¤ ì´ë¦„ì„ ê°€ì ¸ì˜¤ê¸° ìœ„í•´ ì „ì²´ ë°ì´í„°ì…‹ì„ ë¡œë“œí•©ë‹ˆë‹¤.
    full_dataset = CarDataset(
        config.train_directory,
        brand_predictions_path=config.brand_predictions_path,
        brand_info_path=config.brand_info_path,
        transform=None,
    )
    class_names = full_dataset.classes
    has_brand_features = full_dataset.brand_classes is not None

    print(f"Number of classes: {len(class_names)}")
    if has_brand_features:
        print(f"Number of brand classes: {len(full_dataset.brand_classes)}")

    # ë¸Œëœë“œ ëª¨ë¸ ë¡œë“œ
    brand_model, brand_info = load_brand_model(config, device)

    # í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ë¡œë“œ
    if config.use_tta:
        tta_transform = get_tta_transforms(config.image_size, config.mean, config.std)
        test_dataset = CarDataset(
            config.test_directory,
            brand_predictions_path=config.brand_predictions_path,
            brand_info_path=config.brand_info_path,
            tta_transforms=tta_transform,
            is_test=True,
        )
    else:
        test_dataset = CarDataset(
            config.test_directory,
            brand_predictions_path=config.brand_predictions_path,
            brand_info_path=config.brand_info_path,
            transform=get_val_transform(config.image_size, config.mean, config.std),
            is_test=True,
        )

    print(f"Test dataset size: {len(test_dataset)}")

    # í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ëŒ€í•œ ë¸Œëœë“œ ì˜ˆì¸¡ ìƒì„±
    test_brand_predictions = generate_test_brand_predictions(
        brand_model, brand_info, test_dataset, device
    )

    # í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ì— ë¸Œëœë“œ ì˜ˆì¸¡ ì¶”ê°€
    if test_brand_predictions:
        test_dataset.brand_predictions.update(test_brand_predictions)
        print("âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¸Œëœë“œ ì˜ˆì¸¡ ì—…ë°ì´íŠ¸ ì™„ë£Œ")

    # ë©”ì¸ ëª¨ë¸ë“¤ ë¡œë“œ
    models = get_models(
        num_classes=len(class_names),
        brand_classes=len(full_dataset.brand_classes)
        if full_dataset.brand_classes
        else None,
    )

    # ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ
    for i, model in enumerate(models):
        model_path = os.path.join(
            config.model_directory, f"best_{i}.pth"
        )
        if os.path.exists(model_path):
            model.load_state_dict(torch.load(model_path, map_location=device))
            print(f"âœ… Model {i} loaded from {model_path}")
        else:
            print(
                f"âš ï¸  Model {i} weights not found at {model_path}"
            )

        model.to(device)
        model.eval()

    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë”
    test_loader = torch.utils.data.DataLoader(
        test_dataset,
        batch_size=config.batch_size
        // (config.tta_batch_size_divisor if config.use_tta else 1),
        shuffle=False,
        num_workers=4,
        pin_memory=True,
    )

    # ì˜ˆì¸¡ ìˆ˜í–‰
    results = []
    print("ğŸ”® ëª¨ë¸ ì˜ˆì¸¡ ì‹œì‘...")

    with torch.no_grad():
        for batch_data in tqdm(test_loader, desc="Evaluating"):
            if config.use_tta:
                # TTA ì‚¬ìš© ì‹œ
                if isinstance(batch_data, tuple) and len(batch_data) == 2:
                    images, brand_features = batch_data
                    images = images.to(device)
                    brand_features = brand_features.to(device)
                    probabilities = predict_with_tta(models, images, brand_features)
                else:
                    # batch_dataê°€ í…ì„œì¸ì§€ í™•ì¸
                    if isinstance(batch_data, torch.Tensor):
                        images = batch_data.to(device)
                    else:
                        # ë¦¬ìŠ¤íŠ¸ë‚˜ ë‹¤ë¥¸ í˜•íƒœì¸ ê²½ìš° ì²˜ë¦¬
                        images = torch.stack(batch_data).to(device) if isinstance(batch_data, list) else batch_data
                        images = images.to(device)
                    probabilities = predict_with_tta(models, images)
            else:
                # TTA ë¯¸ì‚¬ìš© ì‹œ
                if isinstance(batch_data, tuple) and len(batch_data) == 2:
                    images, brand_features = batch_data
                    images = images.to(device)
                    brand_features = brand_features.to(device)
                    probabilities = predict(models, images, brand_features)
                else:
                    # batch_dataê°€ í…ì„œì¸ì§€ í™•ì¸
                    if isinstance(batch_data, torch.Tensor):
                        images = batch_data.to(device)
                    else:
                        # ë¦¬ìŠ¤íŠ¸ë‚˜ ë‹¤ë¥¸ í˜•íƒœì¸ ê²½ìš° ì²˜ë¦¬
                        images = torch.stack(batch_data).to(device) if isinstance(batch_data, list) else batch_data
                        images = images.to(device)
                    probabilities = predict(models, images)

            for prob in probabilities.cpu():
                result = {
                    class_names[i]: prob[i].item() for i in range(len(class_names))
                }
                results.append(result)
    
    # ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
    predictions = pd.DataFrame(results)

    # sample_submission íŒŒì¼ ë¡œë“œ
    submission = pd.read_csv("sample_submission.csv", encoding="utf-8-sig")

    # í´ë˜ìŠ¤ ìˆœì„œ ë§ì¶”ê¸°
    class_columns = submission.columns[1:]
    predictions = predictions[class_columns]

    # submission íŒŒì¼ì— ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥
    submission[class_columns] = predictions.values
    submission.to_csv("submission.csv", index=False, encoding="utf-8-sig")

    print("âœ… Submission file created: submission.csv")

    # íŒŒì¼ í¬ê¸° í™•ì¸
    file_size = os.path.getsize("submission.csv") / (1024 * 1024)
    print(f"ğŸ“ Submission file size: {file_size:.1f}MB")

    if file_size < 25:
        print("âš ï¸  íŒŒì¼ í¬ê¸°ê°€ ì‘ìŠµë‹ˆë‹¤. ë°ì´í„° ëˆ„ë½ ê°€ëŠ¥ì„±ì„ í™•ì¸í•˜ì„¸ìš”.")


if __name__ == "__main__":
    evaluate()
